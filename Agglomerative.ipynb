{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agglomerative:\n",
    "    __valid_linkage = ['single', 'complete', 'average', 'group average']\n",
    "    \n",
    "    def __init__(self, n_clusters = 2, linkage = 'single'):\n",
    "        if (linkage not in self.__valid_linkage):\n",
    "            raise ValueError(\"Unknown linkage type %s.\"\n",
    "                             \"Valid options are %s\" % (linkage,\n",
    "                                                       self.__valid_linkage))\n",
    "        if (n_clusters < 1):\n",
    "            raise ValueError(\"Invalid value of n_clusters, got %d. Must be at least 1\" % n_clusters)\n",
    "        self.__n_clusters = n_clusters\n",
    "        self.__linkage = linkage\n",
    "        self.__dist_mat = None\n",
    "        self.__n_data = 0\n",
    "        self.__n_attr = 0\n",
    "        self.__data = None\n",
    "    \n",
    "    def fit(self, data):\n",
    "        if (len(data) < 2):\n",
    "            raise ValueError(\"Need at ,east 2 instance of data\")\n",
    "        self.__data = data\n",
    "        self.__n_data = len(data)\n",
    "        self.__n_attr = len(data[0])\n",
    "        self.__clusters = []\n",
    "        for i in range(0, self.__n_data):\n",
    "            self.__clusters.append([i])\n",
    "        while (len(self.__clusters) > self.__n_clusters):\n",
    "            #print(\"Current clusters: \" + str(self.__clusters))\n",
    "            min_dist = self.dist(0, 1)\n",
    "            min_index = (0, 1)\n",
    "            #print(\"Current min: \"+str(min_dist)+\" between cluster \"+str(min_index))\n",
    "            for i in range(0, len(self.__clusters)-1):\n",
    "                for j in range(i+1, len(self.__clusters)):\n",
    "                    temp = self.dist(i, j)\n",
    "                    #print(\"    Check distance between cluster \"+str(i)+\",\"+str(j)+\" = \"+str(temp))\n",
    "                    if (temp < min_dist):\n",
    "                        min_dist = temp\n",
    "                        min_index = (i, j)\n",
    "                        #print(\"        Found new min: \"+str(min_dist)+\" between cluster \"+str(min_index))\n",
    "            #print(\"Merge cluster \"+str(min_index))\n",
    "            self.merge(min_index[0], min_index[1])\n",
    "        self.labels_ = self.getLabels()\n",
    "        return self\n",
    "    \n",
    "    def merge(self, i, j):\n",
    "        #print(self.__clusters)\n",
    "        #print(i, j)\n",
    "        #print(\"Merge item \"+str(self.__clusters[i])+\" and \"+str(self.__clusters[j]))\n",
    "        for item in self.__clusters[j]:\n",
    "            self.__clusters[i].append(item)\n",
    "        del(self.__clusters[j])\n",
    "    \n",
    "    def dist(self, i, j):\n",
    "        if (self.__linkage == 'single'):\n",
    "            return self.mindist(i, j)\n",
    "        elif (self.__linkage == 'complete'):\n",
    "            return self.maxdist(i, j)\n",
    "        elif (self.__linkage == 'average'):\n",
    "            return self.cendist(i, j)\n",
    "        elif (self.__linkage == 'group average'):\n",
    "            return self.avgdist(i, j)\n",
    "    \n",
    "    def mindist(self, i, j):\n",
    "        result = self.dist_idx(self.__clusters[i][0], self.__clusters[j][0])\n",
    "        for itemi in self.__clusters[i]:\n",
    "            for itemj in self.__clusters[j]:\n",
    "                temp = self.dist_idx(itemi, itemj)\n",
    "                #print(\"        Data \"+str(itemi)+\" and \"+str(itemj)+\" has distance \"+str(temp))\n",
    "                if (temp < result):\n",
    "                    result = temp\n",
    "        return result\n",
    "    \n",
    "    def maxdist(self, i, j):\n",
    "        result = self.dist_idx(self.__clusters[i][0], self.__clusters[j][0])\n",
    "        for itemi in self.__clusters[i]:\n",
    "            for itemj in self.__clusters[j]:\n",
    "                temp = self.dist_idx(itemi, itemj)\n",
    "                #print(\"        Data \"+str(itemi)+\" and \"+str(itemj)+\" has distance \"+str(temp))\n",
    "                if (temp > result):\n",
    "                    result = temp\n",
    "        return result\n",
    "    \n",
    "    def avgdist(self, i, j):\n",
    "        result = 0\n",
    "        for itemi in self.__clusters[i]:\n",
    "            for itemj in self.__clusters[j]:\n",
    "                result += self.dist_idx(itemi, itemj)\n",
    "                #print(\"        Data \"+str(itemi)+\" and \"+str(itemj)+\" has distance \"+str(temp))\n",
    "        return float(result) / float(len(self.__clusters[i]) * len(self.__clusters[j]))\n",
    "    \n",
    "    def cendist(self, i, j):\n",
    "        ceni = np.repeat(0, self.__n_attr).tolist()\n",
    "        for idx in self.__clusters[i]:\n",
    "            for p in range(0, self.__n_attr):\n",
    "                ceni[p] += self.__data[idx][p]\n",
    "        for p in range(0, self.__n_attr):\n",
    "            ceni[p] = float(ceni[p]) / float(len(self.__clusters[i]))\n",
    "            \n",
    "        cenj = np.repeat(0, self.__n_attr).tolist()\n",
    "        for idx in self.__clusters[j]:\n",
    "            for p in range(0, self.__n_attr):\n",
    "                cenj[p] += self.__data[idx][p]\n",
    "        for p in range(0, self.__n_attr):\n",
    "            cenj[p] = float(cenj[p]) / float(len(self.__clusters[j]))\n",
    "        \n",
    "        return self.dist_data(ceni, cenj)\n",
    "    \n",
    "    def dist_idx(self, i, j):\n",
    "        return self.dist_data(self.__data[i], self.__data[j])\n",
    "    \n",
    "    def dist_data(self, item1, item2):\n",
    "        result = 0;\n",
    "        for i in range(0, self.__n_attr):\n",
    "            result += pow((item1[i] - item2[i]), 2)\n",
    "        return math.sqrt(result)\n",
    "    \n",
    "    def getLabels(self):\n",
    "        result = np.repeat(-1, self.__n_data)\n",
    "        for i in range(0, self.__n_clusters):\n",
    "            for idx in self.__clusters[i]:\n",
    "                result[int(idx)] = i\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contoh pemakaian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "iris = pd.read_csv('Iris.csv')\n",
    "iris = iris.drop(labels='Id', axis=1)\n",
    "iris_data = iris.values[:,:-1]\n",
    "iris_label = iris.values[:,-1]\n",
    "species_encoder = LabelEncoder().fit(iris_label)\n",
    "iris_label = species_encoder.transform(iris_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Linkage Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Agglomerative(n_clusters=3, linkage='single').fit(iris_data)\n",
    "mat = confusion_matrix(model.labels_, iris_label)\n",
    "purity = float(mat[0].max() + mat[1].max() + mat[2].max()) / float(mat.sum())\n",
    "purity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Linkage Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Agglomerative(n_clusters=3, linkage='complete').fit(iris_data)\n",
    "mat = confusion_matrix(model.labels_, iris_label)\n",
    "purity = float(mat[0].max() + mat[1].max() + mat[2].max()) / float(mat.sum())\n",
    "purity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Linkage Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Agglomerative(n_clusters=3, linkage='average').fit(iris_data)\n",
    "mat = confusion_matrix(model.labels_, iris_label)\n",
    "purity = float(mat[0].max() + mat[1].max() + mat[2].max()) / float(mat.sum())\n",
    "purity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Average Linkage Purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Agglomerative(n_clusters=3, linkage='group average').fit(iris_data)\n",
    "mat = confusion_matrix(model.labels_, iris_label)\n",
    "purity = float(mat[0].max() + mat[1].max() + mat[2].max()) / float(mat.sum())\n",
    "purity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
